{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab939d3-f6c6-4dc8-b203-162d8affb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11cea5d-8571-430e-991c-cee4a164fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pickle as pkl\n",
    "import hist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from analyzer.core import modules as all_modules\n",
    "from analyzer.plotting.core_plots import *\n",
    "from analyzer.plotting.simple_plot import Plotter\n",
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "loadStyles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454420b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "file_name=\"../analyzerout/chargino_reco.pkl\"\n",
    "data = pkl.load(open(file_name, 'rb'))\n",
    "histos = data[\"histograms\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad036334",
   "metadata": {},
   "outputs": [],
   "source": [
    "m4 = histos[\"m14_vs_m24\"][\"Skim_QCDInclusive2018\",...]\n",
    "new_m4 = m4.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13691fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_m4.reset()\n",
    "v = np.random.multivariate_normal([1000,1500],[[10000,0],[0,36000]],1000)\n",
    "new_m4.fill(v[:,0],v[:,1],weight=1)\n",
    "m4=new_m4\n",
    "#m4 = histos[\"m14_m\"][\"Skim_QCDInclusive2018\",...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f91a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = 1100\n",
    "m4_real = m4\n",
    "x,y = [x.centers for x in m4_real.axes]\n",
    "X,Y = np.meshgrid(x,y)\n",
    "points = np.stack((X.ravel(),Y.ravel()), axis=1)\n",
    "print(points)\n",
    "train_x = torch.from_numpy(points)\n",
    "train_y = torch.from_numpy(m4_real.values().ravel())\n",
    "print(train_y)\n",
    "#train_y = train_y - train_y.mean(dim=-1,keepdim=True)\n",
    "\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(ard_num_dims=2) \n",
    "          # gpytorch.kernels.RBFKernel(active_dims=torch.tensor([1,0])) * \n",
    "          # gpytorch.kernels.RBFKernel(active_dims=torch.tensor([0,1])) * \n",
    "          # gpytorch.kernels.RBFKernel(active_dims=torch.tensor([1,1])) \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "# initialize likelihood and model\n",
    "v = torch.from_numpy(m4_real.variances())\n",
    "likelihood = gpytorch.likelihoods.FixedNoiseGaussianLikelihood(noise=v, learn_additional_noise=True)\n",
    "v = torch.sqrt(v) \n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329c255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is for running the notebook in our testing framework\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "for param_name, param in model.named_parameters():\n",
    "    print(f'Parameter name: {param_name:42} value = {param}')\n",
    "    \n",
    "#model.covar_module.base_kernel.lengthscale = 205\n",
    "model.covar_module.outputscale = 10\n",
    "model.covar_module.base_kernel.lengthscale=torch.tensor([600,600])\n",
    "model.train()\n",
    "\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam([{\"params\": model.covar_module.base_kernel.parameters(), \"lr\": 25},\n",
    "                              {\"params\": [model.covar_module.raw_outputscale], \"lr\": 1e9},\n",
    "                              {\"params\": model.mean_module.parameters(), \"lr\": 500}\n",
    "                            ]\n",
    "                           )\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(100):\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(train_x)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    for param_name, param in model.named_parameters():\n",
    "        print(f'Parameter name: {param_name:42} value = {param}')\n",
    "    #print('Iter %d - Loss: %.3f   lengthscale: %.3f  scale: %.3f  mean:%0.3f'  % (\n",
    "      # i + 1,  loss.item(),\n",
    "      #  model.covar_module.base_kernel..item(),\n",
    "     #   model.covar_module.outputscale.item(),\n",
    "      #  model.mean_module.constant.item()\n",
    "   # ))\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3fe951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get into evaluation (predictive posterior) mode\n",
    "model.eval()\n",
    "likelihood.eval()\n",
    "#model.covar_module.base_kernel.lengthscale = 10\n",
    "\n",
    "# Test points are regularly spaced along [0,1]\n",
    "# Make predictions by feeding model through likelihood\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(1000, 3100,1500)\n",
    "    #test_x = train_x.flatten()\n",
    "    observed_pred = likelihood(model(test_x),noise=torch.zeros_like(test_x).flatten())\n",
    "    #observed_pred = model(test_x)\n",
    "    print(model.mean_module.constant)\n",
    "    print(observed_pred.mean)\n",
    "    # Initialize plot\n",
    "    f, ax = plt.subplots()\n",
    "\n",
    "    # Get upper and lower confidence bounds\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    # Plot training data as black stars\n",
    "    #ax.plot(train_x.numpy(), train_y.numpy(), 'k*')\n",
    "    ax.errorbar(train_x.numpy(), train_y.numpy(), yerr=v, fmt='o', markersize=3)\n",
    "\n",
    "    # Plot predictive means as blue line\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    # Shade between the lower and upper confidence bounds\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc9559",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77427385",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.linspace(0,30,40)\n",
    "train_x = train_x[(train_x < 4 ) | (train_x > 10)]\n",
    "#train_y = torch.ones_like(train_x) * 2\n",
    "train_y = torch.exp(-0.03 * train_x)\n",
    "#train_y = torch.reshape(train_y)\n",
    "# We will use the simplest form of GP model, exact inference\n",
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel() \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "# initialize likelihood and model\n",
    "likelihood = gpytorch.likelihoods.GaussianLikelihood()\n",
    "model = ExactGPModel(train_x, train_y, likelihood)\n",
    "likelihood.noise =0.01\n",
    "model.covar_module.base_kernel.lengthscale = 10\n",
    "model.train()\n",
    "likelihood.train()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.1)\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model)\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(train_x)\n",
    "    loss = -mll(output, train_y)\n",
    "    loss.backward()\n",
    "    for param_name, param in model.named_parameters():\n",
    "        pass\n",
    "        #print(f'Parameter name: {param_name:42} value = {param}')\n",
    "    optimizer.step()\n",
    "\n",
    "likelihood.eval()\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    test_x = torch.linspace(0,30,200)\n",
    "    observed_pred = likelihood(model(test_x),noise=torch.zeros_like(test_x).flatten()) \n",
    "    f, ax = plt.subplots()\n",
    "    lower, upper = observed_pred.confidence_region()\n",
    "    ax.plot(train_x.numpy(), train_y.numpy(), \"ko\", markersize=4,)\n",
    "    ax.plot(test_x.numpy(), observed_pred.mean.numpy(), 'b')\n",
    "    ax.fill_between(test_x.numpy(), lower.numpy(), upper.numpy(), alpha=0.5)\n",
    "    ax.legend(['Observed Data', 'Mean', 'Confidence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed055143",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25879900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a24e182",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb01468b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmsmlenv",
   "language": "python",
   "name": "cmsmlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
